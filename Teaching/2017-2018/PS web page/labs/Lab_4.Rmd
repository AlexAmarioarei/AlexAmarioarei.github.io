---
title: "Laborator 4"
subtitle: Exerciții de probabilități în R
output:
  pdf_document:
    includes:
      before_body: tex/body.tex
      in_header: tex/preamble.tex
    keep_tex: yes
    number_sections: yes
  html_document:
    code_folding: show
    css: labs_css/labs.css
    keep_md: yes
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
    includes:
      in_header: lab_header/lab_header.html
      after_body: lab_header/lab_footer.html
  word_document:
    fig_caption: yes
    highlight: pygments
    keep_md: yes
    reference_docx: template/template.docx
    toc: no
---

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 60
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

Obiectivul acestui laborator este de a rezolva câteva probleme de teoria probabilităților cu ajutorul limbajului R.  

```{r, echo=FALSE}
library(knitr)

knitr::opts_chunk$set(comment = NA, prompt = FALSE, collapse = TRUE, error = TRUE, fig.align = 'center')

source("functions/getOutputFormat.R")

if (getOutputFormat() == "pdf_document"){
  source("functions/figureNumber_tex.R")
  source("functions/tableNumber_tex.R")
}else{
  source("functions/figureNumber.R")
  source("functions/tableNumber.R")
}


```

# Generarea unei variabile aleatoare discrete

```{block, type = "rmdexercise"}
Definiți o funcție care să genereze un eșantion de talie $n$ dintr-o distribuție discretă definită pe mulțimea $\{x_1,\dots,x_N\}$ cu probabilitățile $\{p_1,\dots,p_N\}$. Pentru început încercați cu v.a. de tip Bernoulli. 
```

Avem următoarea funcție:

```{r}
GenerateDiscrete = function(n = 1, x, p, err = 1e-15){
  # talia esantionului
  # x alfabetul 
  # p probabilitatile
  lp = length(p)
  lx = length(x)
  
  # verify if x and p have the same size 
  if(abs(sum(p)-1)>err | sum(p>=0)!=lp){
    
    stop("suma probabilitatilor nu este 1 sau probabilitatile sunt mai mici decat 0")
    
  }else if(lx!=lp){
    
    stop("x si p ar trebui sa aiba aceeasi marime")
    
  }else{
    out = rep(0, n)
    
    indOrderProb = order(p, decreasing = TRUE) # index
    pOrdered = p[indOrderProb] # rearrange the values of the probabilities 
    xOrdered = x[indOrderProb] # rearramnge the values of x
    
    # u = runif(n) # generate n uniforms
    pOrderedCS = cumsum(pOrdered)
    
    for (i in 1:n){
      u = runif(1)
      
      k = min(which(u<=pOrderedCS))
      out[i] = xOrdered[k]
    }
  }
  
  return(out)
}
```

și pentru a o putea testa să considerăm cazul repartițiilor Poisson și Geometrică:

  a) Poisson  
  
```{r, fig.align='center'}
# Poisson
hist(GenerateDiscrete(10000, x = 0:50, 
                      p = dpois(0:50, 5)), 
     probability = TRUE, 
     breaks = seq(-0.5,49.5, by = 1), 
     xlim = c(-0.5, 20),
     col = "grey80",
     main = "Repartitia Poisson",
     xlab = "X",
     ylab = "Densitatea")

lines(0:50,
      dpois(0:50, 5), 
      type = "l", 
      col = "brown3", lty = 2, lwd = 2)
```

  b) Geometrică
  
```{r, fig.align='center'}
# Geometric
hist(GenerateDiscrete(10000, x = 0:100, 
                      p = dgeom(0:100, 0.3)), 
     probability = TRUE, 
     breaks = seq(-0.5,99.5, by = 1),
     xlim = c(-0.5, 20),
     col = "grey80",
     main = "Repartitia Geometrica",
     xlab = "X",
     ylab = "Densitatea")

lines(0:100,
      dgeom(0:100, 0.3), 
      type = "l", 
      col = "brown3", lty = 2, lwd = 2)
```

# Funcția de repartiție pentru variabile aleatoare

```{block, type = "rmdexercise"}
Scrieți o funcție în `R` care să traseze graficul funcției de repartitie a unei distribuții date. Verificați și documentația funcției `ecdf`. 
```

Definim următoarea funcție:

```{r}
cdfPlot = function(dist, title, err = 1e-10){
  # dist - repartitia discreta (sau discretizata)
  lp = length(dist)
  
  if (abs(sum(dist)-1)>err | sum(dist>=0)!=lp){
    stop("Eroare: vectorul de probabilitati nu formeaza o repartitie")
  }else{
    x = 0:(lp-1) # ia valori in 1:lp
    cp = cumsum(dist)
    
    plot(x, cp, type = "s", lty = 3, 
         xlab = "x", 
         ylab = "F", 
         main = paste("Functia de repartitie:", title), 
         ylim = c(0,1), 
         col = "grey",
         bty = "n")
    abline(h = 0, lty = 2, col = "grey")
    abline(h = 1, lty = 2, col = "grey")
    for(i in 1:(lp-1)){
      lines(c(x[i], x[i+1]), c(cp[i], cp[i]), lwd = 2)
    }
    points(x,cp, col = "black", pch = 20, cex = 0.85)
  }
}
```

Pentru a testa această funcție să considerăm repartițiile discrete: 

  a) Binomiala: $\mathcal{B}(100, 0.3)$

```{r, fig.align='center', out.width="80%"}
cdfPlot(dist = dbinom(0:100, 100, 0.3), title = "B(100,0.3)")
```

  b) Poisson: $Pois(0.3)$ și $Pois(5)$

```{r, fig.align='center'}
par(mfrow = c(1, 2))

cdfPlot(dist = dpois(0:20, 0.3), title = "Pois(0.3)")
cdfPlot(dist = dpois(0:50, 5), title = "Pois(5)")
```

  c) Geometrica: $Geom(0.3)$

```{r, fig.align='center', out.width="80%"}
par(mfrow = c(1,1))
cdfPlot(dist = dgeom(0:100, 0.3), title = "Geom(0.3)")
```

și repartiția continuă: 

  a) Normala: $\mathcal{N}(0,1)$

```{r, fig.align='center', out.width="80%"}
cdfPlot(dist = dnorm(seq(-5,5,0.01))/100, title = "N(0,1)", err = 1e-1)
```

# Aproximarea Poisson și Normală a Binomialei

```{block, type = "rmdexercise"}
Ilustrați grafic aproximarea Poisson și normală a repartiției binomiale. 
```

Scopul acestei probleme este de a ilustra grafic aproximarea legii binomile cu ajutorul repartiției Poisson și a a normalei. 

Pentru o v.a. $X$ repartizată binomial de parametrii $n$ și $p$ ($q = 1-p$) funcția de masă este 

$$
f_{n,p}(k)=\mathbb{P}(X=k)=\binom{n}{k}p^k(1-p)^{n-k}
$$ 

iar funcția de repartiție este 

$$
F_{n,p}(k) = \mathbb{P}(X\leq k) = \sum_{x=0}^{k}\binom{n}{x}p^x(1-p)^{n-x}.
$$ 

## Aproximarea Poisson

Dacă $n\to\infty$ ($n$ este mare) și $p\to 0$ ($p$ este mic, evenimentele sunt rare) așa încât $np\to\lambda$ atunci se poate verifica cu ușurință că 

$$
f_{n,p}(k)\approx f_{\lambda}(k)=e^{-\lambda}\frac{\lambda^k}{k!}.
$$

Mai exact, avem că dacă $k$ este mic în comparație cu $n$ atunci

\begin{align*}
  \binom{n}{k}p^k &= \frac{n(n-1)\cdots(n-k+1)}{k!}\left(\frac{\lambda}{n}\right)^k \\
                  &= 1\times\left(1-\frac{1}{n}\right)\times\cdots\times\left(1-\frac{k-1}{n}\right)\frac{\lambda^k}{k!}\\
                  &\approx \frac{\lambda^k}{k!}
\end{align*}

și 

$$
  \log(1-p)^{n-k} = (n-k)\log\left(1-\frac{\lambda}{n}\right)\approx n\left(-\frac{\lambda}{n}\right)
$$

ceea ce conduce la $(1-p)^{n-k}\approx e^{-\lambda}$. Combinând cele două aproximări obținem 

$$
  \binom{n}{k}p^k(1-p)^{n-k} \approx \frac{\lambda^k}{k!}e^{-\lambda}.
$$

Pentru a ilustra acuratețea acestei aproximări vom folosi instrucțiunile `R` `dbinom` și `dpois` care permit calcularea funcțiilor de masă $f_{n,p}(k)$ și $f_{\lambda}(k)$.  


```{r}
AppBP <- function(n,p,a,b){
    lambda <- n*p
    x<- matrix(numeric((b-a+1)*3),ncol=3,
               dimnames = list(a:b,c("Binomiala","Poisson","Eroarea Absoluta")))
    x[,1]<-dbinom(a:b,n,p)
    x[,2]<-dpois(a:b,lambda)
    x[,3]<-abs(x[,1]-x[,2])
    error <- max(abs(x[,3]))
    
    return(list(x = as.data.frame(x), error = error, param = c(n, p, lambda)))
}

# Functie care ilustreaza aproximarea Binomial vs. Poisson

pl <- function(n,p,a,b){
    clr<-c("#E69F00", "#56B4E9")# culori
    lambda <- n*p
    mx <- max(dbinom(a:b,n,p))
    plot(c(a:b,a:b), c(dbinom(a:b,n,p), dpois(a:b,lambda)), type="n", 
         main = paste("Approx. Poisson pentru binomiala\n n=", 
                      n, ", p = ", p, ", lambda = ",lambda), 
         ylab = "Probabilitatea", xlab="x",
         bty = "n")
    points((a:b)-.15, dbinom(a:b,n,p), type = "h",col = clr[1], lwd = 8)
    points((a:b)+.15, dpois(a:b,lambda), type = "h",col = clr[2], lwd = 8)
    legend(b-b/2, mx, legend = c(paste0("Binomiala(",n,",",p,")"),
                               paste0("Poisson(",lambda,")")), 
           fill = clr, bg="white",
           bty = "n")
}
```

Pentru setul de parametrii $n=20$ și $p=0.3$ avem următorul tabel și următoarea figură

```{r, echo = FALSE}
dat1 = AppBP(20, 0.3, 1, 15)

tab1 = cbind(rownames(dat1$x), dat1$x)
names(tab1)[1] = "k"

kable(tab1, 
      align = "c",
      caption = paste("Aproximarea Poisson la binomiala n =", dat1$param[1], "p =", 
                      dat1$param[2],"lambda =", dat1$param[3], 
                      ". Eroarea (Diferenta in valoare absoluta maxima) = ", 
                      format(dat1$error, digits = 4), "."))
```

```{r, fig.align="center", echo=FALSE}
# pentru n = 10, p = 0.1
pl(20,.3,1,20)
```

iar pentru parametrii $n=100$ și $p=0.01$ obținem

```{r, echo = FALSE}
dat2 = AppBP(100, 0.01, 1, 10)

tab2 = cbind(rownames(dat2$x), dat2$x)
names(tab2)[1] = "k"

kable(tab2, 
      align = "c",
      caption = paste("Aproximarea Poisson la binomiala n =", dat2$param[1], "p =", 
                      dat2$param[2],"lambda =", dat2$param[3], 
                      ". Eroarea (Diferenta in valoare absoluta maxima) = ", 
                      format(dat2$error, digits = 4), "."))
```

```{r, fig.align="center", echo=FALSE}
# pentru n = 100, p = 0.01
pl(100,.01, 1, 10)
```

Pentru funcția de repartiție $F_{n,p}(k)$, folosidn aproximarea Poisson avem că

$$
F_{n,p}(k) \approx F_{\lambda}(k)=\sum_{x=0}^{k}e^{-\lambda}\frac{\lambda^x}{x!}.
$$

## Aproximarea Normală

Să considerăm repartiția binomială $\mathcal{B}(n, p)$ pentru $p = 0.3$ și $n\in\{20, 50, 100, 150, 200\}$ și să trasăm histogramele variabilelor aleatoare care au aceste repartiții ($X_n$) precum și a variabilelor standardizate $Z_n = \frac{X_n-np}{\sqrt{npq}}$.

```{r, fig.align="center", echo=FALSE}
p = 0.3
q = 1-p

nn = c(20, 50, 100, 150, 200)

par(mfrow = c(5, 2),
    mar = c(2,4,1,1))

for (i in nn){
  plot(0:i, 
       dbinom(0:i, i, p), 
       type = "h", 
       # lwd = 1/sqrt(i*p*q), 
       ylim = c(0,0.2), 
       xlim = c(0,100), 
       col = "#56B4E9",
       xlab = "", 
       ylab = paste0("Bin(",i,",",p,")"),
       las = 1,
       lwd = 2,
       cex = 0.8,
       bty = "n")
  
  plot((0:i - i*p)/sqrt(i*p*q), 
       dbinom(0:i, i, p)*sqrt(i*p*q), 
       type = "h", 
       lwd = 4, 
       ylim = c(0,0.5), 
       xlim = c(-4,4), 
       col = "#56B4E9",
       xlab = "", 
       ylab = "",
       las = 1,
       bty = "n",
       cex = 0.8)
}
```

Observăm, pentru graficele din partea stângă, că valoarea maximă se atinge în jurul punctului $n\times 0.3$ pentru fiecare grafic în parte. De asemenea se observă că odată cu creșterea lui $n$ crește și gradul de împrăștiere, cu alte cuvinte crește și abaterea standard ($\sigma_n = \sqrt{npq}$).

Pe de altă parte putem remarca că figurile din partea dreaptă au o formă simetrică, de tip *clopot*, concentrate în jurul lui $0$, fiind translatate în origine și scalate pentru a avea o varianță egală cu $1$. [Abraham de Moivre](https://en.wikipedia.org/wiki/Abraham_de_Moivre)^[de Moivre, A. (1756). *The Doctrine of Chances: or, A Method of Calculating the Probabilities of Events in Play* (Third ed.). New York: Chelsea.] a justificat acest efect (pentru $p=0.5$) încă din 1756 observând că raportul 

$$
  \frac{f_{n,p}(k)}{f_{n,p}(k-1)} = \frac{\frac{n!}{k!(n-k)!}p^kq^{n-k}}{\frac{n!}{(k-1)!(n-k+1)!}p^{k+1}q^{n-k+1}} = \frac{(n-k+1)p}{kq}
$$

pentru $k = 1,2,\ldots,n$. Astfel $f_{n,p}(k)\geq f_{n,p}(k-1)$ dacă și numai dacă $(n+1)p\geq k$ de unde, pentru $n$ fixat, deducem că $f_{n,p}(k)$ atinge valoarea maximă pentru $k_{\max} = \lfloor{(n+1)p\rfloor}\approx np$ (acesta este motivul pentru care fiecare grafic din partea stângă are vârful în jurul punctului $np$). 

Să observăm ce se întâmplă în jurul lui $k_{\max}$. Avem 

$$
\frac{f_{n,p}(k_{\max}+i)}{f_{n,p}(k_{\max}+i-1)} = \frac{(n-k_{\max}-i+1)p}{(k_{\max}+i)q}\approx \frac{(nq-i)p}{(np+i)q} = \frac{1-\frac{i}{nq}}{1+\frac{i}{np}}
$$

și cum (folosind relația $\log(1+x)\approx x$, pentru $x$ în jurul lui $0$)

$$
\log\left(1-\frac{i}{nq}\right) - \log\left(1+\frac{i}{np}\right) \approx -\frac{i}{nq}-\frac{i}{np} = -\frac{i}{npq}
$$ 

deducem, pentru $m\geq 1$ și $k_{\max}+m\leq n$, că

\begin{align*}
  \log\frac{f_{n,p}(k_{\max}+m)}{f_{n,p}(k_{\max})} &= \log\left(\frac{f_{n,p}(k_{\max}+1)}{f_{n,p}(k_{\max})}\times \frac{f_{n,p}(k_{\max}+2)}{f_{n,p}(k_{\max}+1)}\times\cdots\times\frac{f_{n,p}(k_{\max}+m)}{f_{n,p}(k_{\max}+m-1)}\right)\\
  &= \log\frac{f_{n,p}(k_{\max}+1)}{f_{n,p}(k_{\max})}+ \log\frac{f_{n,p}(k_{\max}+2)}{f_{n,p}(k_{\max}+1)}+\cdots+\log\frac{f_{n,p}(k_{\max}+m)}{f_{n,p}(k_{\max}+m-1)}\\
  &\approx \frac{-1-2-\cdots-m}{npq} = -\frac{1}{2}\frac{m^2}{npq}.
\end{align*}

Sumarizând avem, pentru $m$ nu foarte mare, 

$$
  \mathbb{P}(X=k_{\max}+m)\approx f_{n,p}(k_{\max})e^{-\frac{1}{2}\frac{m^2}{npq}}.
$$

Folosind formula lui [Stirling](https://en.wikipedia.org/wiki/Stirling%27s_approximation)^[A se vedea cartea lui Feller, W. (1968). *An Introduction to Probability Theory and Its Applications* (third ed.), Volume 1. New York: Wiley. pag. 52-53 pentru o derivare a formulei lui Stirling.] 

$$
  n!\approx \sqrt{2\pi}n^{n+\frac{1}{2}}e^{-n}
$$

pentru $k = k_{\max}\approx np$, avem

$$
f_{n,p}(k)\approx \frac{1}{\sqrt{2\pi}}\frac{n^{n+\frac{1}{2}}}{(np)^{np+\frac{1}{2}}(nq)^{nq+\frac{1}{2}}}p^{np}q^{nq}= \frac{1}{\sqrt{2\pi npq}}.
$$

Astfel aproximarea de Moivre devine 

$$
  \mathbb{P}(X=k_{\max}+m)\approx \frac{1}{\sqrt{2\pi npq}}e^{-\frac{1}{2}\frac{m^2}{npq}}
$$

și scriind $k$ pentru $k_{\max}+m$ și înlocuind $k_{\max}$ cu $np$ obținem

$$
  \mathbb{P}(X=k)\approx \frac{1}{\sqrt{2\pi npq}}e^{-\frac{1}{2}\frac{(k-np)^2}{npq}} = \frac{1}{\sigma_n\sqrt{2\pi}}e^{-\frac{1}{2}\left(\frac{k-np}{\sigma_n}\right)^2}.
$$

Astfel $mathbb{P}(X=k)$ este aproximativ egală cu aria de sub curba 

$$
  f(x) = \frac{1}{\sigma_n\sqrt{2\pi}}e^{-\frac{1}{2}\left(\frac{x-np}{\sigma_n}\right)^2}
$$
pe intervalul $k-\frac{1}{2}\leq x\leq k+\frac{1}{2}$. 

În mod similar, pentru $0\leq a< b\leq n$, avem 

$$
  \mathbb{P}(a\leq X\leq b) = \sum_{k=a}^{b}f_{n,p}(k) \approx \sum_{k=a}^{k=b}\int_{k+\frac{1}{2}}^{k-\frac{1}{2}}f(x)\,dx = \int_{a}^{b}f(x)\,dx
$$

de unde prin schimbarea de variabilă $y = \frac{x-np}{\sigma_n}$ obținem

$$
  \mathbb{P}(a\leq X\leq b)\approx \frac{1}{\sqrt{2\pi}}\int_{\alpha}^{\beta}e^{-\frac{y^2}{2}}\,dy = \Phi(\beta) - \Phi(\alpha)
$$

unde $\alpha = \frac{a-np-\frac{1}{2}}{\sigma_n}$, $\beta =  = \frac{b-np+\frac{1}{2}}{\sigma_n}$ și $\Phi(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\frac{y^2}{2}}\,dy$.

Aplicând rezultatele de mai sus, în cele ce urmează vom considera două aproximări pentru funcția de repartiție $F_{n,p}(k)$: 

  a) aproximarea normală

$$
F_{n,p}(k) \approx \Phi\left(\frac{k-np}{\sqrt{np(1-p)}}\right).
$$

  b) aproximarea normală cu coeficient de corecție de continuitate 

$$
F_{n,p}(k) \approx \Phi\left(\frac{k+0.5-np}{\sqrt{np(1-p)}}\right).
$$

În practică această ultimă aproximare se aplică atunci când atât $np\geq 5$ cât și $n(1-p)\geq 5$.

Următorul cod crează o funcție care calculează cele trei aproximări pentru funcția de repartiție binomială

```{r}
appBNP <- function(n, p, R = 1000, k = 6) {
  trueval <- pbinom(k, n, p) # adevarata valoare a functiei de repartitie in k
  prob.zcc <- prob.zncc <- prob.pois <- NULL  # initializare
  q = 1-p
  for (i in 1:R) {# repetam procesul de R ori 
    x = rnorm(n, n * p, sqrt(n * p * q)) # generare n v.a. normale de medie np 
    z.cc = ((k + .5) - mean(x))/sd(x) # cu coeficient de corectie
    prob.zcc[i] = pnorm(z.cc)
    z.ncc = (k - mean(x))/sd(x) # fara coeficient de corectie
    prob.zncc[i] = pnorm(z.ncc)    
    y = rpois(n, n * p)
    prob.pois[i] = length(y[y <= k])/n # aproximate Poisson
  }
  list(prob.zcc = prob.zcc, prob.zncc = prob.zncc, 
       prob.pois = prob.pois, trueval = trueval)
}
```

Avem următoarea ilustrație grafică a diferitelor metode de aproximare

```{r, fig.align="center"}
# Plot
R <- 1000
set.seed(10)
out <- appBNP(n = 100, p = .01, k = 2, R = 1000)

plot(1:R, out$prob.pois, type = "l", col = "#E69F00", xlab = "Numar repetari", 
     main = expression(paste("Probabilitatile simulate: ", 
                             n==100, ", ", p==0.01, sep="")),
     ylab = "Probabilitatea", ylim = c(.7, .97),
     bty = "n")
abline(h = out$trueval, col="black", lty=2, lwd=2)
lines(1:R, out$prob.zcc, lty = 1, col = "#56B4E9")
lines(1:R, out$prob.zncc, lty = 1, col = "gray80")
legend("bottomleft", c("Poisson", "Normala (cu factor corectie)", 
                       "Normala (fara factor corectie)"),
       lty = c(1), col = c("#E69F00", "#56B4E9", "gray80"),
       bty = "n")

```

Avem și următorul `boxplot` (discuție ce reprezintă un boxplot) care ne permite să evidențiem care dintre aproximări este mai bună pentru valorile selectate

```{r, fig.align="center"}

# n = 200
set.seed(10)
out <- appBNP(n = 100, p = .01, k = 2, R = 1000)

boxplot(out$prob.pois, boxwex = 0.25, xlim = c(0.5, 1.5),
        col = "#E69F00",
        main = expression(paste("Aproximarea Binomialei: ", 
                                n==100, ", ", p==0.01, sep="")),
        ylab = "Probablitatea", 
        ylim = c(out$trueval - 0.1, out$trueval + 0.15), 
        bty = "n")
boxplot(out$prob.zcc, boxwex = 0.25, at = 1:1 - 0.2, add = T,
        col = "#56B4E9")
boxplot(out$prob.zncc, boxwex = 0.25, at = 1:1 + 0.2, add = T,
        col = "gray80" )
abline(h = out$trueval, col = "red", lty=2)
legend("topleft", c("Poisson", "Normala (cu factor corectie)", 
                    "Normala (fara factor corectie)"), 
       fill = c("#E69F00", "#56B4E9", "gray80"),
       bty = "n")

```



